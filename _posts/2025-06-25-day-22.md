---
layout: post
title: "Day 22 - Fusing Models and Rethinking Strategy"
date: 2025-06-25
author: Ayomide Jeje
permalink: /day22.html
tags: ["Training Ai Models"]

what_i_learned: |
  Today marked a significant turning point in my internship journey. While the early part of the day began with continued frustration over my model’s instability, it ended with a breakthrough that redefined my entire approach to solving the problem. I’ve been working on building a deep learning model to classify ECG signals, and my initial plan centered around using a 1D Convolutional Neural Network (1D CNN). Although the architecture seemed promising on paper, I encountered persistent issues in training: low accuracy, unstable loss, and unconvincing validation results. For a while, I kept trying to fine-tune the CNN in isolation, hoping minor tweaks would resolve the problem. However, today I realized that the limitations weren't just due to hyperparameters — the model needed better structure and support.
That realization led me to adopt a multi-model fusion approach. I began by integrating the 1D CNN with a Bidirectional LSTM (BiLSTM) layer, followed by an attention mechanism. Each part of this fusion served a unique role: the CNN was effective at capturing spatial patterns in the ECG waveform, the BiLSTM provided a deeper understanding of temporal dependencies, and the attention mechanism helped the model focus on the most informative parts of the signal. This combination brought architectural balance and clarity that the standalone CNN lacked.






blockers: |
  No Blockers
reflection: |
 Today was one of those days that reminded me why research is as much about mindset as it is about models. What started as another attempt to fix a frustrating problem turned into a breakthrough — not just in my code, but in the way I approach challenges. For the past few days, I’ve been trying to get a 1D CNN model to work on ECG signal data. The idea was simple: use convolution to capture key waveform patterns and classify them. But no matter how many times I adjusted the layers, learning rate, or batch size, the model just wouldn’t perform well. Accuracy was shaky, loss wouldn’t stabilize, and I kept running into shape mismatches and unsatisfying validation results. This morning, I took a step back and asked myself: Am I trying to make the wrong thing work harder, instead of building something smarter? That question led me to experiment with a fusion approach. Instead of relying solely on the CNN, I combined it with a Bidirectional LSTM to capture the temporal structure of the ECG signals, then added an attention layer to help the model focus on the most informative time steps. It wasn’t an easy change — I had to rethink input shapes, merge outputs, and debug new issues — but something about it felt right. For the first time, the architecture felt balanced.


---
