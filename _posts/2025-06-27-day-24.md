---
layout: post
title: "Day 24 - Fusing Models and Moving Forward"
date: 2025-06-27
author: Ayomide Jeje
permalink: /day24.html
tags: ["Training Ai Models"]

what_i_learned: |
 I began the day by revisiting my previous models. My 1D CNN was functional, but I felt it could perform better if it incorporated richer data representations. That thought led me down the path of model fusion — combining different data perspectives into a hybrid model to improve accuracy and robustness. After some planning, I initiated the fusion of multiple input representations: the time-domain ECG waveform, frequency-domain transformations, and spectrograms. My goal was to create a hybrid system that could learn from all these aspects simultaneously. I started integrating a 1D CNN for temporal features, paired it with a Bidirectional LSTM to capture sequential dependencies, and explored combining it with metadata features for enhanced context. This wasn’t just about throwing models together — I had to carefully manage input shapes, tensor concatenation, and ensure the architecture remained computationally efficient. Debugging took time, especially aligning dimensions and ensuring label consistency across modalities. But by early afternoon, I had a working pipeline and kicked off initial training. Training was slow — GPUs can only do so much with complex models and large datasets — but I monitored the logs closely. I saw promising validation accuracy in early epochs, and the model didn’t overfit right away, which was a relief. I also saved the best-performing checkpoints using callbacks to avoid wasting computation.








blockers: |
  No Blockers
reflection: |
   What stood out most today was the importance of data perspective — one signal can tell different stories depending on how you process it. Time-domain features might show rhythm, but frequency features capture subtle abnormalities, and spectrograms make patterns more visually interpretable. Fusing them lets the model see the full picture — just like a doctor would. I also learned how powerful model modularity is: by building each component in a reusable way, I was able to experiment faster without rewriting code.The early results were decent — validation accuracy showed promise — but today wasn’t about the numbers. It was about realizing how much more powerful models can become when you feed them richer, multi-angle information. And honestly, it made me reflect on something deeper: maybe the way we train models is a reflection of how we learn too. You don’t just look at life through one lens. You bring in memories, emotions, knowledge — layers. And the more layers you learn to combine, the clearer the picture becomes.





---
